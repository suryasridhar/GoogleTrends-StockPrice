{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqDyN9+O5QGK3IzbC8JvlH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryasridhar/GoogleTrends-StockPrice/blob/develop/GoogleTrends_StockPrice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IETkxkLab5fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from pytrends.request import TrendReq\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "def fetch_google_trends(ticker, timeframe='now 1-d'):\n",
        "    pytrends = TrendReq(hl='en-US', tz=360)\n",
        "    kw_list = [ticker]\n",
        "    pytrends.build_payload(kw_list, cat=0, timeframe=timeframe, geo='', gprop='')\n",
        "\n",
        "    # Add a delay to prevent hitting rate limits\n",
        "    time.sleep(1)  # Wait 1 second between requests\n",
        "\n",
        "    trends_data = pytrends.interest_over_time()\n",
        "    if not trends_data.empty:\n",
        "        return trends_data[ticker].iloc[-1]  # Return the most recent trend score\n",
        "    else:\n",
        "        return 0  # If no data available, return 0\n",
        "\n",
        "# Fetch historical stock data using yfinance\n",
        "def fetch_stock_data(ticker, days=30):\n",
        "    end_date = datetime.datetime.now()\n",
        "    start_date = end_date - datetime.timedelta(days=days)\n",
        "    stock = yf.Ticker(ticker)\n",
        "    historical_data = stock.history(start=start_date, end=end_date)\n",
        "    return historical_data\n",
        "\n",
        "# Prepare training data: get historical stock data and Google Trends for each day\n",
        "def prepare_training_data(ticker, days=30):\n",
        "    historical_data = fetch_stock_data(ticker, days=days)\n",
        "    dates = historical_data.index\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for date in dates[:-1]:\n",
        "        google_trends_score = fetch_google_trends(ticker, timeframe=f'{date.strftime(\"%Y-%m-%d\")} {date.strftime(\"%Y-%m-%d\")}')\n",
        "\n",
        "        high_today = historical_data.loc[date, 'High']\n",
        "        low_today = historical_data.loc[date, 'Low']\n",
        "        next_day = date + datetime.timedelta(days=1)\n",
        "\n",
        "        if next_day in historical_data.index:\n",
        "            max_next_day = historical_data.loc[next_day, 'High']\n",
        "            X.append([high_today, low_today, google_trends_score])\n",
        "            y.append(max_next_day)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Scale data using MinMaxScaler\n",
        "def scale_data(X, y):\n",
        "    scaler_X = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "    return X_scaled, y_scaled, scaler_X, scaler_y\n",
        "\n",
        "# Define and train a neural network model\n",
        "def train_neural_network(X, y, epochs=50, batch_size=8):\n",
        "    model = Sequential([\n",
        "        Dense(64, input_dim=X.shape[1], activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Predict using the trained neural network\n",
        "def predict_next_day_max_nn(model, scaler_X, scaler_y, high_today, low_today, google_trends_score):\n",
        "    X_input = np.array([[high_today, low_today, google_trends_score]])\n",
        "    X_scaled = scaler_X.transform(X_input)\n",
        "    y_pred_scaled = model.predict(X_scaled)\n",
        "    return scaler_y.inverse_transform(y_pred_scaled)[0, 0]\n",
        "\n",
        "# Backtest the neural network model\n",
        "def backtest_neural_network(ticker, model, scaler_X, scaler_y, days=10):\n",
        "    historical_data = fetch_stock_data(ticker, days=days + 1)\n",
        "    results = []\n",
        "\n",
        "    for i in range(days):\n",
        "        date_today = historical_data.index[-(days - i)]\n",
        "        date_tomorrow = historical_data.index[-(days - i - 1)]\n",
        "\n",
        "        high_today = historical_data.loc[date_today, 'High']\n",
        "        low_today = historical_data.loc[date_today, 'Low']\n",
        "        actual_max = historical_data.loc[date_tomorrow, 'High']\n",
        "\n",
        "        # Fetch Google Trends score for the current day\n",
        "        google_trends_score = fetch_google_trends(ticker, timeframe=f'{date_today.strftime(\"%Y-%m-%d\")} {date_today.strftime(\"%Y-%m-%d\")}')\n",
        "\n",
        "        # Predict the next day's max price\n",
        "        predicted_max = predict_next_day_max_nn(model, scaler_X, scaler_y, high_today, low_today, google_trends_score)\n",
        "\n",
        "        results.append({\n",
        "            \"Date\": date_tomorrow.strftime('%Y-%m-%d'),\n",
        "            \"Predicted Max\": predicted_max,\n",
        "            \"Actual Max\": actual_max\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Main function to run the script\n",
        "def main(ticker_symbol):\n",
        "    print(f\"Fetching data and Google Trends analysis for {ticker_symbol}...\")\n",
        "\n",
        "    # Prepare training data\n",
        "    X, y = prepare_training_data(ticker_symbol, days=30)\n",
        "    X_scaled, y_scaled, scaler_X, scaler_y = scale_data(X, y)\n",
        "\n",
        "    # Train neural network\n",
        "    print(\"Training neural network...\")\n",
        "    model = train_neural_network(X_scaled, y_scaled)\n",
        "\n",
        "    # Predict max price for today\n",
        "    today_data = fetch_stock_data(ticker_symbol, days=1)\n",
        "    high_today = today_data['High'].values[-1]\n",
        "    low_today = today_data['Low'].values[-1]\n",
        "    google_trends_score = fetch_google_trends(ticker_symbol, timeframe='now 1-d')\n",
        "    predicted_max_price = predict_next_day_max_nn(model, scaler_X, scaler_y, high_today, low_today, google_trends_score)\n",
        "\n",
        "    print(f\"**Predicted Max Price for Today ({ticker_symbol}):** ${predicted_max_price:.2f}\")\n",
        "\n",
        "    # Backtest for the last 10 days\n",
        "    print(f\"Backtesting for {ticker_symbol} over the last 10 days...\")\n",
        "    backtest_results = backtest_neural_network(ticker_symbol, model, scaler_X, scaler_y, days=10)\n",
        "\n",
        "    print(backtest_results)\n",
        "    return backtest_results\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    ticker = input(\"Enter the stock ticker symbol (e.g., AAPL, MSFT): \")\n",
        "    main(ticker)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "aB3MpBliZNyR",
        "outputId": "0b7a0c8e-e734-45f4-b14a-6030d41244c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the stock ticker symbol (e.g., AAPL, MSFT): MSFT\n",
            "Fetching data and Google Trends analysis for MSFT...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TooManyRequestsError",
          "evalue": "The request failed: Google returned a response with code 429",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a78fc3950bb6>\u001b[0m in \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the stock ticker symbol (e.g., AAPL, MSFT): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-a78fc3950bb6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(ticker_symbol)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Prepare training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker_symbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a78fc3950bb6>\u001b[0m in \u001b[0;36mprepare_training_data\u001b[0;34m(ticker, days)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mgoogle_trends_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_google_trends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{date.strftime(\"%Y-%m-%d\")} {date.strftime(\"%Y-%m-%d\")}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mhigh_today\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistorical_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a78fc3950bb6>\u001b[0m in \u001b[0;36mfetch_google_trends\u001b[0;34m(ticker, timeframe)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait 1 second between requests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrends_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrends_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrends_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Return the most recent trend score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytrends/request.py\u001b[0m in \u001b[0;36minterest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# make the request and parse the returned json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         req_json = self._get_data(\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTEREST_OVER_TIME_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstatus_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoo_many_requests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTooManyRequestsError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
          ]
        }
      ]
    }
  ]
}